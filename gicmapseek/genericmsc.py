#!/usr/bin/env python

## Copyright (C) 2005-2006 Graham I Cummins
## This program is free software; you can redistribute it and/or modify it under 
## the terms of the GNU General Public License as published by the Free Software 
## Foundation; either version 2 of the License, or (at your option) any later version.
## 
## This program is distributed in the hope that it will be useful, but WITHOUT ANY 
## WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
## PARTICULAR PURPOSE. See the GNU General Public License for more details.
## 
## You should have received a copy of the GNU General Public License along with 
## this program; if not, write to the Free Software Foundation, Inc., 59 Temple 
## Place, Suite 330, Boston, MA 02111-1307 USA
## 
from numpy import *
from numpy.random import normal
import time
def nonzero1d(a):
	return nonzero(a)[0]
		


class MapSeeker(object):
	'''Base class for map seeking circuits. This class provides the basic MSC iteration algorithm, but the details of how transformations are performed are left as stub methods to be filled in by subclasses.'''
	
	default={'maxiter':200, 'kappa':.5, 'precondition':2, 'checkdomain':True,
			'gdiscard':0.001, 'persist':True, 'rule':'kappa', 'mdiscard':0.0}
	
	def __init__(self, opts=None):
		op = {}
		op.update(self.default)
		op.update(opts or {})
		self.opts=op	
		self.layers=[]
		self.track=None
		self.solv=None
		self.iter=0
		
	def report(self, s, important=1):
		sil=self.opts.get('silent', 0)
		if not important>sil:
			return
		print(s)			
	
	
	def bestPath(self):
		return [argmax(self.layers[li]['gain']) for li in range(len(self.layers))] 
	
	def run(self):
		'''This method requires that the algorithm has been prepped with a source and target image. '''	
		state=self.preCheck()
		st=time.time()
		self.solv=None
		while not state and self.iter<self.opts['maxiter']:
			self.report("Iteration %i" % self.iter, 3)
			state=self.iterate()
		st= time.time()-st	
		self.report("Run complete (%.2f sec)" % st, 10)
		if not self.solv:
			self.report("Algorithm did not converge", 10)
			self.solv=('error', state)
		return self.solv	
		
	def prep(self, n, source, target):
		'''Set up n layers with initial weights, and set the source and target image.'''
		self.source=source
		self.layers=[]
		self.iter=0
		for i in range(n):
			self.layers.append({'source':None, 'target':None, 'gain':ones(self.nMaps(i)),  'dead':zeros(self.nMaps(i))})
		self.layers[-1]['target']=target
				
	def preCheck(self):
		'''Do any pre-run testing here. Return a True value to abort the upcoming run. '''
		return 0
		
	def doMap(self, layer, index, forward, input):
		'''Subclasses must implement this function. Apply the "index"th mapping of the "layerth" layer to the data in input. If forward is False, apply the inverse map. Return images should be normalized'''
		
	
	def describeMap(self, layer, index, forward):
		'''Subclasses must implement this function. Return a string saying what the "index"th mapping of the "layerth" layer does. If forward is False, describe the inverse map.'''
		
	def describeSolution(self):
		if not self.solv:
			self.report('No solution')
		else:
			s=""
			for i, m in enumerate(self.solv):
				s+="Layer %i: %s\n" % (i, self.describeMap(i, m, True))
			self.report(s)
		
	def addImages(self, loi):
		'''Return the image generated by superposition of the images is the list loi. If this operation might be different for different layers, the subclass implementation should be appropriately polymorphic on the content of loi. The superclass version works for the case where images are numpy arrays. Also works with gicmapseek.sparse instances'''
		sv=loi[0]
		for rv in loi[1:]:
			sv=sv+rv
		return sv
		
	def normImage(self, source):
		'''return a version of the image source in which the sum of the elements is 1.0. The superclass version works on numpy arrays (or sparse)'''
		if source.sum()==0:
			return source
		return source/source.sum()
		
	def applyBias(self, layer, source):
		'''Apply the bias (penalty function) field associated to layer to the image source and return the resulting image. The superclass method does nothing (it returns the unmodified source image) '''
		return source	
		
	def scaleImage(self, i, g):
		'''Return the image i scaled (usually multiplied) by the weight g. The superclass version works for the case where images are numpy arrays (or sparse).'''
		return i*g
		
	def matchImage(self, source, target):
		'''Return a match quality (scalar float) between the images source and target. The superclass version works for the case where images are numpy arrays. (or sparse)'''
		m = (source*target).sum()
		if isnan(m):
			print source, target
			raise StandardError("NaN comparison")
		return m
		
	def nMaps(self, layer):
		'''Subclasses must implement this. Return the number of maps in layer'''
	
	def onDomain(self, source, target):
		'''Return the image source with all values that are zero in target zeroed. The superclass version works for the case where images are numpy arrays. (or sparse)'''
		return source*(target!=0)
	
	def learnkappa(self, g, q):
		mask=q==0
		q=q/q.max()
		q=self.opts['kappa']*(1-q)
		g=where(mask, 0.0, g-q)
		return g
		
	def matchproportional(self, g, q):
		return 	g*q	
	
	def minkappaqp(self, g, m):
		q=m/m.max()
		q=self.opts['kappa']*(1-q)
		g=minimum(g*m, g-q)
		return g
	
	def onFail(self):
		#return False to continue a run
		self.report("No overlap possible", 2)
		if not self.opts['persist']:
			self.report("Unsolvable", 9)
			return -1	
		change=0
		for i in range(len(self.layers)):
			pass 
		return -1
			
	
	def iterate(self):
		'''Does the work in each iteration. Called by "run".'''
		converged=1
		ts=time.time()
		for li in range(len(self.layers)-1, 0, -1):
			source = self.layers[li]['target']
			maps=[]
			for mi, g in enumerate(self.layers[li]['gain']):
				if g:
					maps.append(self.scaleImage(self.doMap(li, mi, False, source), g))
			out = self.normImage(self.applyBias(li-1, self.addImages(maps)))
			if self.opts['checkdomain'] and li<=len(self.layers)/2 and self.layers[li-1]['source']!=None:
				out = self.onDomain(out, self.layers[li-1]['source'])
			self.layers[li-1]['target']=out
		self.iter+=1
		source = self.source
		for li in range(len(self.layers)):
			maps=[]
			match=[]
			for mi, g in enumerate(self.layers[li]['gain']):
				if g:
					maps.append(self.applyBias(li, self.scaleImage(self.doMap(li, mi, True, source), g)))
					match.append(self.matchImage(maps[-1], self.layers[li]['target']))
				else:
					match.append(0)
			source=self.normImage(self.addImages(maps))
			if self.opts['checkdomain'] and li>len(self.layers)/2: 
				source = self.onDomain(source, self.layers[li]['target'])
			self.layers[li]['source']=source
			if self.opts.get('dryrun'):
				continue
			match = array(match)
			if not any(match):
				print "match failed"
				status = self.onFail()
				return status
			if self.opts['mdiscard']:
				match=where(match<(match.max()*self.opts['mdiscard']), 0, match)
			self.layers[li]['dead']=nonzero(self.layers[li]['gain']==0)[0]
			g=self.learningrules[self.opts['rule']](self, self.layers[li]['gain'], match)	
			g=maximum(0, g/g.max())
			if self.opts['gdiscard']:
				g=where(g<self.opts['gdiscard'], 0.0, g)
			if g.sum()>1.5:
				converged=0	
				if all(abs(g-self.layers[li]['gain'])<.0001):
					self.report("noise at %i" % li, 2)
					g=g+normal(0, .1, g.shape)	
					g=maximum(0, g/g.max())
			self.layers[li]['gain']=g
		if converged:
			self.solv=self.bestPath()	
		return converged

	
	learningrules={
		'kappa':learnkappa,
		'qp':matchproportional,
		'fast':minkappaqp,
		}	
		
class ExampleMapSeekingSubclass(MapSeeker):
	'''Simple map seeking subclass that assumes that all layers implement the same set of 4 maps, which are horizontal and vertical one-element shifts. Images are numpy arrays, so the image manipulation methods from the base class don't need to be overloaded. Also, since all layers are the same, init and prep don't need to be overloaded. The size of the msc is determined by the value of "n" passed to prep. This MSC doesn't use bias fields '''
	inverses = [1,0,3,2]
	def doMap(self, layer, index, forward, input):
		if not forward:
			index=self.inverses[index]
		out = zeros_like(input)
		if index==0:
			#translate right
			out[:,1:]=input[:,:-1]
		if index==1:
			#translate left
			out[:,:-1]=input[:,1:]
		if index==2:
			#translate up
			out[:-1,:]=input[1:,:]
		if index==3:
			#translate down
			out[1:,:]=input[:-1,:]
		return out
		
	def describeMap(self, layer, index, forward):
		if not forward:
			index=self.inverses[index]
		out = zeros_like(input)
		if index==0:
			s="translate right"
		if index==1:
			s="translate left"
		if index==2:
			s="translate up"
		if index==3:
			s="translate down"
		return s
	
	def nMaps(self, layer):
		return 4
			
if __name__=='__main__':
	i=zeros((5,5))
	i[1,1]=1.0
	t=zeros((5,5))
	t[3,3]=1.0
	m=ExampleMapSeekingSubclass()
	m.prep(4,i,t)
	r=m.run()
	print r
	m.describeSolution()
	

	
			
	